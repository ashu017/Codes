{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basics DS stuffs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP39vXtlEq7mCQFSR1BCZXe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashu017/Codes/blob/main/Basics_DS_stuffs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J7_zot1KiTo"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "dataset = pd.read_csv('...\\\\User_Data.csv') \n",
        "\n",
        "# input feature selction\n",
        "x = dataset.iloc[:, [2, 3]].values \n",
        "  \n",
        "# output \n",
        "y = dataset.iloc[:, 4].values\n",
        "\n",
        "from sklearn.cross_validation import train_test_split \n",
        "xtrain, xtest, ytrain, ytest = train_test_split( \n",
        "        x, y, test_size = 0.25, random_state = 0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "sc_x = StandardScaler() \n",
        "xtrain = sc_x.fit_transform(xtrain)  \n",
        "xtest = sc_x.transform(xtest) \n",
        "  \n",
        "print (xtrain[0:10, :]) \n",
        "\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "classifier = LogisticRegression(random_state = 0) \n",
        "classifier.fit(xtrain, ytrain) \n",
        "\n",
        "y_pred = classifier.predict(xtest) \n",
        "\n",
        "from sklearn.metrics import confusion_matrix \n",
        "cm = confusion_matrix(ytest, y_pred) \n",
        "  \n",
        "print (\"Confusion Matrix : \\n\", cm) \n",
        "\n",
        "from sklearn.metrics import accuracy_score \n",
        "print (\"Accuracy : \", accuracy_score(ytest, y_pred)) \n",
        "\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LkrVCg3M83K"
      },
      "source": [
        "#Normalisation\n",
        "\n",
        "def z_score(df):\n",
        "    # copy the dataframe\n",
        "    df_std = df.copy()\n",
        "    # apply the z-score method\n",
        "    for column in df_std.columns:\n",
        "        df_std[column] = (df_std[column] - df_std[column].mean()) / df_std[column].std()\n",
        "        \n",
        "    return df_std\n",
        "    \n",
        "# call the z_score function\n",
        "df_cars_standardized = z_score(df_cars)\n",
        "\n",
        "df_cars_standardized\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# create a scaler object\n",
        "std_scaler = StandardScaler()\n",
        "std_scaler\n",
        "# fit and transform the data\n",
        "df_std = pd.DataFrame(std_scaler.fit_transform(df_cars), columns=df_cars.columns)\n",
        "\n",
        "df_std"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}